{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled92.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN4jaWSYDbLh4AVJOQYNp+J",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DevanshSaini18/Social-distancing-detection-YOLOv3/blob/main/violation-detection%20using%20Yolov3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ho3XYln5HK5X"
      },
      "source": [
        "### Pafy is a Python library to download YouTube content and retrieve metadata. ... In order to install pafy we use the command given below\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wu8zCLYrNWW"
      },
      "source": [
        "!pip install pafy\n",
        "!pip install youtube_dl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45UUSvkGHN4O"
      },
      "source": [
        "### In order to download yolov3 weights, config and coco.names file we run the below cell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLyr0Pg6rQOB"
      },
      "source": [
        "!wget https://pjreddie.com/media/files/yolov3.weights\n",
        "!wget https://raw.githubusercontent.com/pjreddie/darknet/master/cfg/yolov3.cfg\n",
        "!wget https://raw.githubusercontent.com/pjreddie/darknet/master/data/coco.names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXzNZyluHlSu"
      },
      "source": [
        "### OpenCV-Python(cv2) is a library of Python bindings designed to solve computer vision problems\n",
        "### Imutils are a series of convenience functions to make basic image processing functions such as translation, rotation, resizing etc\n",
        "### Numpy is used for trigonometric, statistical, and algebraic routines\n",
        "### cv2_imshow to display frames of video in google colab(cv2.imshow does not work in colab)\n",
        "### clear_output to clear output after each frame is displayed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2Jx6_YIrQLy"
      },
      "source": [
        "import pafy\n",
        "import cv2\n",
        "import imutils\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "from IPython.display import clear_output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7c3JrKxEIsL6"
      },
      "source": [
        "### Using pafy to use youtube video of given url"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T--lcCUKrQJu"
      },
      "source": [
        "url = \"https://youtu.be/2bKXv_XviFc?t=00:50\"\n",
        "video = pafy.new(url)\n",
        "best = video.getbest()\n",
        "vs = cv2.VideoCapture(best.url)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h9ALXEgEI2GO"
      },
      "source": [
        "### Setting labelPaths and extracting label names from coco.names list"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TdEdlpsgtEx1"
      },
      "source": [
        "labelsPath = \"/content/coco.names\"\n",
        "LABELS = []\n",
        "with open(labelsPath) as f:\n",
        "\tline = f.readlines()\n",
        "\tfor class_name in line:\n",
        "\t\tclass_name = class_name.strip(\"\\n\")\n",
        "\t\tLABELS.append(class_name)\n",
        "print(\"Length of LABELS : \",len(LABELS))\n",
        "person_index = LABELS.index(\"person\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JnhstRGDMnzN"
      },
      "source": [
        "### Setting weights path and config path \n",
        "### 1) yolov3.weights : The pre-trained weights\n",
        "### 2) yolov3.cfg : The configuration file.\n",
        "### Giving the configuration and weight files for the model and load the network using them.\n",
        "### setting the preferable target to cv.dnn.DNN_TARGET_OPENCL to run it on a GPU\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2X0s49JJHQy"
      },
      "source": [
        "weightsPath = \"/content/yolov3.weights\"\n",
        "configPath = \"/content/yolov3.cfg\"\n",
        "net = cv2.dnn.readNetFromDarknet(configPath, weightsPath) \n",
        "net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)\n",
        "\n",
        "net.setPreferableTarget(cv2.dnn.DNN_TARGET_OPENCL)\n",
        "\n",
        "ln = net.getLayerNames()                                    \n",
        "ln = [ln[i[0] - 1] for i in net.getUnconnectedOutLayers()]  \n",
        "print(ln)                                           "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gm1fqJ78QOXe"
      },
      "source": [
        "### a) MIN_CONF - Defining the min confidence required to accept a detected box . If our model have detected a box having confidence lesser than MIN_CONF then it would neglect that box\n",
        "### b) NMS_THRESH - Defining the min threshold iou(Intersection over Union) value required for diferent boxes to be considered detecting the same object. Box with higher score would be kept and other would be removed\n",
        "### c) max_dist - Defining the minimum allowable distance between two persons (on pixel plane) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3r_4ft0JObB"
      },
      "source": [
        "MIN_CONF = 0.3\n",
        "NMS_THRESH = 0.4\n",
        "max_dist = 50"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9m4XLIh7RPeX"
      },
      "source": [
        "### Measures euclidean distance between the center of two boxes (on pixel plane)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MeKTKZxF3CLw"
      },
      "source": [
        "def find_dist(box1,box2):\n",
        "\tcentre1 = ((box1[0]+box1[2])/2,(box1[1]+box1[3])/2)\n",
        "\tcentre2 = ((box2[0]+box2[2])/2,(box2[1]+box2[3])/2)\n",
        "\tdist = np.sqrt((centre1[0]-centre2[0])**2+(centre1[1]-centre2[1])**2)\n",
        "\treturn (dist < max_dist)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqDkfHTkRfj7"
      },
      "source": [
        "### Find whether two boxes violate the minimum allowable distance condition. And  returns a list of pairs of each pair found violating and a set of all indices found violating with any other box"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8B82JUdU2LPB"
      },
      "source": [
        "def find_violations(results):\n",
        "    length = len(results)\n",
        "    too_close_pairs = []\n",
        "    too_close_set = set()\n",
        "    for i in range(length):\n",
        "        for j in range(i):\n",
        "            dist_bool = find_dist(results[i],results[j])\n",
        "            if dist_bool:\n",
        "                too_close_pairs.append((i,j))\n",
        "                too_close_set.add(i)\n",
        "                too_close_set.add(j)\n",
        "    return too_close_pairs,too_close_set"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eD8xUY6jSDef"
      },
      "source": [
        "### Draws a box using opencv with the set of indices of all the people violating the min distance condition \n",
        "### Red Boxes for violation  and green for non - violation  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbv4x6I668a5"
      },
      "source": [
        "def draw_rect(results,too_close_set):\n",
        "\tfor i in range(len(results)):\n",
        "\t\tviolated = True if i in too_close_set else False\n",
        "\t\tbox = results[i]\n",
        "\t\t(startX,startY,endX,endY) = box\n",
        "\t\tif violated:\n",
        "\t\t\t# draw red rectangle\n",
        "\t\t\tcv2.rectangle(frame, (startX, startY), (endX, endY),(0,0,255), 2)\n",
        "\t\telse:\n",
        "\t\t\tcv2.rectangle(frame, (startX, startY), (endX, endY),(0,255,0), 2)\n",
        "\treturn "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDobmFCfSe33"
      },
      "source": [
        "### Draws a line between each pair found violating the min distance condition (i.e they are closer to each other than min_dist)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3nJWhOOh8M-k"
      },
      "source": [
        "def draw_line(results,too_close_pair):\n",
        "    for i,j in too_close_pair:\n",
        "        box1 = results[i]\n",
        "        box2 = results[j]\n",
        "        centre1 = ((box1[0]+box1[2])/2,(box1[1]+box1[3])/2)\n",
        "        centre2 = ((box2[0]+box2[2])/2,(box2[1]+box2[3])/2)\n",
        "        cv2.line(frame, (int(centre1[0]),int(centre1[1])), (int(centre2[0]), int(centre2[1])), (255, 255, 0), thickness=1, lineType=1)        \n",
        "    return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NbbNAE_jSpG2"
      },
      "source": [
        "### For recognizing Person object and its location \n",
        "### If the detected object is having confidence > MIN_CONF then it would be accepted else ignored\n",
        "### Later on applying NMS suppression to remove multiple boxes denoting same object,i.e if iou value of two boxes is greater than NMS_Thresh then box with higher score will remain and other would be removed  \n",
        "### At last returing the coordinates of bounding box found"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTwSleH__qim"
      },
      "source": [
        "def get_coordinates_of_people(frame,nn,ln,person_index):\n",
        "\tblob = cv2.dnn.blobFromImage(frame, 1 / 255.0, (416, 416),swapRB=True, crop=False)\n",
        "\tnet.setInput(blob)\n",
        "\tlayerOutputs = net.forward(ln)   \n",
        "\tboxes = []\n",
        "\tconfidences = []\n",
        "\t(H, W) = frame.shape[:2]\n",
        "\tfor output in layerOutputs:\n",
        "\t\tfor detection in output:\n",
        "\t\t\tclassID = np.argmax(detection[5:])\n",
        "\t\t\tconfidence = detection[5:][classID]\n",
        "\t\t\tif classID == person_index and confidence > MIN_CONF:\n",
        "\t\t\t\tbox = detection[0:4] * np.array([W, H, W, H])\n",
        "\t\t\t\t(centerX, centerY, width, height) = box.astype(\"int\")\n",
        "\t\t\t\tx = int(centerX - (width / 2))\n",
        "\t\t\t\ty = int(centerY - (height / 2))\n",
        "\t\t\t\tboxes.append([x, y, int(width), int(height)])\n",
        "\t\t\t\tconfidences.append(float(confidence))\n",
        "\tidxs = cv2.dnn.NMSBoxes(boxes, confidences, MIN_CONF, NMS_THRESH) \n",
        "\tresults = []\n",
        "\tif len(idxs) == 0:\n",
        "\t\treturn []\n",
        "\tfor i in idxs.flatten():\n",
        "\t\t(x, y) = (boxes[i][0], boxes[i][1])\n",
        "\t\t(w, h) = (boxes[i][2], boxes[i][3])\n",
        "\t\tresults.append((x, y, x + w, y + h))\n",
        "\treturn results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9eTSYmxUISo"
      },
      "source": [
        "### Using opencv for frame by fame analysis for object detection and calling required functions for detection and drawing showing and clearing output "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "US1QBtMXrQFg"
      },
      "source": [
        "count = 0\n",
        "while True:\n",
        "\t(grabbed, frame) = vs.read()\n",
        "\tif count%20!=0:\n",
        "\t\tcount =  count + 1\n",
        "\t\tcontinue\n",
        "\tcount = count + 1\n",
        "\tif not grabbed:\n",
        "\t\tbreak\n",
        "\tframe = imutils.resize(frame, width=700)\n",
        "\tresults = get_coordinates_of_people(frame, net, ln,person_index)\n",
        "\ttoo_close_pairs, too_close_set =  find_violations(results)\n",
        "\tdraw_rect(results,too_close_set)\n",
        "\tdraw_line(results,too_close_pairs)\n",
        "\tcv2_imshow(frame)\n",
        "\tclear_output(wait=True)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
